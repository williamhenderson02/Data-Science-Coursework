{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/will/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data visualisation and handlng libraries \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl import Workbook\n",
    "import openpyxl\n",
    "import os\n",
    "import re\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted exisitng file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load od1.xlsx and create a worksheet\n",
    "wb1 = load_workbook(filename = \"od1.xlsx\")\n",
    "ws1 = wb1[\"Sheet1\"]\n",
    "\n",
    "#load od2.xlsx and create a worksheet\n",
    "wb2 = load_workbook(filename = \"od2.xlsx\")\n",
    "ws2 = wb2[\"Sheet1\"]\n",
    "\n",
    "#create a new third workbook and sheet which will  be used to store the merged data\n",
    "merged_wb = Workbook()\n",
    "merged_ws = merged_wb.active\n",
    "\n",
    "#check if od.xlsx exists and delete\n",
    "if os.path.isfile(\"od.xlsx\"):\n",
    "\n",
    "    print(\"deleted exisitng file\")\n",
    "    os.remove(\"od.xlsx\")\n",
    "\n",
    "#loop for rows in a worksheet using iter_rows\n",
    "#start at row 2 as row 1 is column headings\n",
    "#values_only = True used to compare cell values rather than cell objects\n",
    "for row1 in ws1.iter_rows(min_row = 2, values_only = True):\n",
    "\n",
    "    for row2 in ws2.iter_rows(min_row = 2, values_only = True):\n",
    "        \n",
    "        #check if shared columns are equal for a row\n",
    "        if row1[3] == row2[0] and row1[4] == row2[1] and row1[5] == row2[2] and row1[6] == row2[3] and row1[7] == row2[7]:\n",
    "\n",
    "            #append row to worksheet if equal\n",
    "            merged_ws.append(row1[0:7] + row2[4:])\n",
    "\n",
    "row_num = 0\n",
    "\n",
    "#regular expression to match ID\n",
    "id_regex = r'#(\\d+)'\n",
    "\n",
    "#dictionary to store ids\n",
    "id_dict = {}\n",
    "\n",
    "#loop for rows in merged sheet starting at 1 as no column heading exist yet\n",
    "for row in merged_ws.iter_rows(min_row = 1):\n",
    "    \n",
    "    #re. search returns a match object\n",
    "    #.group returns the string if there is a match\n",
    "    id_val = re.search(id_regex, row[0].value).group(1)\n",
    "\n",
    "    #convert string to int\n",
    "    id_dict[row_num] = int(id_val)\n",
    "\n",
    "    row_num += 1\n",
    "\n",
    "#create a list containing the order the rows should be in\n",
    "sorted_rows = [r[0] for r in sorted(id_dict.items(), key = lambda x: x[1])]\n",
    "\n",
    "for idx, row_num in enumerate(sorted_rows):\n",
    "\n",
    "    #move the rows so they are sorted after row 244\n",
    "    merged_ws.move_range(f\"A{row_num + 1}:M{row_num + 1}\", rows = 245 - row_num + idx)\n",
    "\n",
    "#remove the now empty rows 1-244\n",
    "merged_ws.delete_rows(1,245)\n",
    "\n",
    "#insert a new row for the headers\n",
    "merged_ws.insert_rows(1)\n",
    "header_row = merged_ws[1]\n",
    "\n",
    "#header titles\n",
    "headers = [\"ID\", \"Age\", \"Gender\", \"Diagnosis\", \"dioptre_1\", \"dioptre_2\", \"astigmatism\", \"Phakic/Pseudophakic\", \"Pneumatic\", \"Perkins\", \"Pachymetry\", \"Axial_Length\", \"VF_MD\"]\n",
    "\n",
    "#add the headers to the header row\n",
    "for header in headers:\n",
    "\n",
    "    header_row[headers.index(header)].value = header\n",
    "\n",
    "#loop through the cells in the header row\n",
    "for cell in header_row:\n",
    "\n",
    "    #format header row\n",
    "    cell.font = openpyxl.styles.Font(bold = True)\n",
    "    cell.alignment = openpyxl.styles.Alignment(horizontal = 'center')\n",
    "    border = openpyxl.styles.Border(left=openpyxl.styles.Side(style='thin'),right=openpyxl.styles.Side(style='thin'),top=openpyxl.styles.Side(style='thin'),bottom=openpyxl.styles.Side(style='thin'))\n",
    "    cell.border = border\n",
    "\n",
    "#insert row for grouped headers\n",
    "merged_ws.insert_rows(1)\n",
    "grouped_row = merged_ws[1]\n",
    "\n",
    "#grouped header titles\n",
    "grouped_headers = [\"Age\", \"Gender\", \"Diagnosis\", \"Refractive_Defect\", \"\", \"\", \"Phakic/Pseudophakic\", \"IOP\", \"\", \"Pachymetry\", \"Axial_Length\", \"VF_MD\"]\n",
    "\n",
    "#add the headers to the grouped headers row\n",
    "for header in grouped_headers:\n",
    "\n",
    "    grouped_row[grouped_headers.index(header) + 1].value = header\n",
    "\n",
    "#loop through each cell in the grouped header row\n",
    "for cell in grouped_row:\n",
    "\n",
    "    #format the grouped headers\n",
    "    cell.font = openpyxl.styles.Font(bold = True)\n",
    "    cell.alignment = openpyxl.styles.Alignment(horizontal = 'center')\n",
    "    border = openpyxl.styles.Border(left=openpyxl.styles.Side(style='thin'),right=openpyxl.styles.Side(style='thin'),top=openpyxl.styles.Side(style='thin'),bottom=openpyxl.styles.Side(style='thin'))\n",
    "    cell.border = border\n",
    "\n",
    "#load os sheet\n",
    "oswb = load_workbook(filename = \"os.xlsx\")\n",
    "osws = oswb[\"Sheet1\"]\n",
    "\n",
    "#merge cells to created grouped headers\n",
    "merged_ws.merge_cells('E1:G1')\n",
    "merged_ws.merge_cells('I1:J1')\n",
    "\n",
    "#loop through the columns in os.xslx\n",
    "for column in osws.columns:\n",
    "\n",
    "    #get the width of each column\n",
    "    col_index = column[1].column_letter\n",
    "    col_width = osws.column_dimensions[col_index].width\n",
    "\n",
    "    #set column width for od equal to os columns\n",
    "    if col_width == 13.0:\n",
    "\n",
    "        merged_ws.column_dimensions[col_index].width = col_width /1.475\n",
    "\n",
    "    else:\n",
    "        #set column width for od equal to os columns\n",
    "        merged_ws.column_dimensions[col_index].width = col_width\n",
    "\n",
    "#save sheet to workbook\n",
    "merged_wb.save('od.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_data = pd.read_excel(\"od.xlsx\")\n",
    "os_data = pd.read_excel(\"os.xlsx\")\n",
    "\n",
    "od_data['Axial_Length'].fillna(26, inplace = True)\n",
    "os_data['Axial_Length'].fillna(26, inplace = True)\n",
    "\n",
    "od_data.drop(index=0, inplace=True)\n",
    "os_data.drop(index=0, inplace=True)\n",
    "\n",
    "od_data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "os_data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "#print(os_data['Diagnosis'].value_counts(dropna = False))\n",
    "#print(od_data['Phakic/Pseudophakic'].value_counts(dropna = False))\n",
    "#print(os_data['Phakic/Pseudophakic'].value_counts(dropna = False))\n",
    "\n",
    "diagnosis_mapping = {\n",
    "    'Healthy': 'healthy',\n",
    "    'heal.': 'healthy',\n",
    "    'heaLthy': 'healthy',\n",
    "    'healthY': 'healthy',\n",
    "    'sus': 'suspicious',\n",
    "    'Suspicious': 'suspicious',\n",
    "    'Glaucoma': 'glaucoma',\n",
    "    'glau.': 'glaucoma'\n",
    "}\n",
    "\n",
    "os_data['Diagnosis'] = os_data['Diagnosis'].apply(lambda x: ' '.join([diagnosis_mapping.get(word, word).strip() for word in x.split()]))\n",
    "\n",
    "for i, value in os_data['Diagnosis'].items():\n",
    "\n",
    "    tokens = word_tokenize(value.lower())\n",
    "\n",
    "    for j, token in enumerate(tokens):\n",
    "\n",
    "        if token in diagnosis_mapping:\n",
    "\n",
    "            tokens[j] = diagnosis_mapping[token]\n",
    "\n",
    "    os_data.at[i, 'Diagnosis'] = ' '.join(tokens)\n",
    "\n",
    "gender_le = LabelEncoder()\n",
    "diagnosis_le = LabelEncoder()\n",
    "phakic_le = LabelEncoder()\n",
    "\n",
    "od_data['Gender'] = gender_le.fit_transform(od_data['Gender'])\n",
    "od_data['Diagnosis'] = diagnosis_le.fit_transform(od_data['Diagnosis'])\n",
    "od_mask = od_data['Phakic/Pseudophakic'].isna()\n",
    "od_data.loc[~od_mask, 'Phakic/Pseudophakic'] = phakic_le.fit_transform(od_data.loc[~od_mask, 'Phakic/Pseudophakic'])\n",
    "\n",
    "os_data['Gender'] = gender_le.fit_transform(os_data['Gender'])\n",
    "os_data['Diagnosis'] = diagnosis_le.fit_transform(os_data['Diagnosis'])\n",
    "os_mask = od_data['Phakic/Pseudophakic'].isna()\n",
    "os_data.loc[~os_mask, 'Phakic/Pseudophakic'] = phakic_le.fit_transform(os_data.loc[~os_mask, 'Phakic/Pseudophakic'])\n",
    "\n",
    "imputer = IterativeImputer()\n",
    "imputed_od = imputer.fit_transform(od_data)\n",
    "imputed_os = imputer.fit_transform(os_data)\n",
    "\n",
    "imputed_od = pd.DataFrame(imputed_od, columns=od_data.columns)\n",
    "imputed_os = pd.DataFrame(imputed_os, columns=os_data.columns)\n",
    "\n",
    "imputed_od['Gender'] = gender_le.inverse_transform(imputed_od['Gender'].astype(int))\n",
    "imputed_od['Diagnosis'] = diagnosis_le.inverse_transform(imputed_od['Diagnosis'].astype(int))\n",
    "imputed_od['Phakic/Pseudophakic'] = phakic_le.inverse_transform(imputed_od['Phakic/Pseudophakic'].astype(int))\n",
    "\n",
    "imputed_os['Gender'] = gender_le.inverse_transform(imputed_os['Gender'].astype(int))\n",
    "imputed_os['Diagnosis'] = diagnosis_le.inverse_transform(imputed_os['Diagnosis'].astype(int))\n",
    "imputed_os['Phakic/Pseudophakic'] = phakic_le.inverse_transform(imputed_os['Phakic/Pseudophakic'].astype(int))\n",
    "\n",
    "imputed_od.drop_duplicates()\n",
    "imputed_os.drop_duplicates()\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "for column in imputed_od.columns:\n",
    "\n",
    "    if(imputed_od[column].dtype) == 'float64':\n",
    "\n",
    "        od_mean = np.mean(imputed_od[column])\n",
    "        os_mean = np.mean(imputed_os[column])\n",
    "\n",
    "        od_std = np.std(imputed_od[column])\n",
    "        os_std = np.std(imputed_os[column])\n",
    "\n",
    "        od_z_scores = (imputed_od[column] - od_mean) / od_std\n",
    "        os_z_scores = (imputed_os[column] - os_mean) / os_std\n",
    "\n",
    "        od_outliers = np.abs(od_z_scores) > threshold\n",
    "        os_outliers = np.abs(os_z_scores) > threshold\n",
    "\n",
    "        imputed_od = imputed_od[~od_outliers]\n",
    "        imputed_os = imputed_os[~os_outliers]\n",
    "\n",
    "imputed_od.to_excel(\"od_cleaned.xlsx\")\n",
    "imputed_os.to_excel(\"os_cleaned.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
